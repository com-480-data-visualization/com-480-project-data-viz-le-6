{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIS-Data Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_YEAR = 1967\n",
    "END_YEAR = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ski-DB parser\n",
    "\n",
    "**[Website](https://www.ski-db.com/)**\n",
    "\n",
    "**[Profiles](https://www.ski-db.com/db/profiles/beat_feuz_sui_511383.php)**, of the form `https://www.ski-db.com/db/profiles/<id>.php`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeasonURL(year, isMen=True):\n",
    "    \"\"\"Get the Ski-DB page for a particular season.\n",
    "    \"\"\"\n",
    "    if not START_YEAR <= year <= END_YEAR:\n",
    "        raise ValueError(f\"An invalid WC year was given (from {START_YEAR} to {END_YEAR}).\")\n",
    "    gender = 'm' if isMen else 'f'\n",
    "    endSeason = year % 100\n",
    "    startSeason = (year-1) % 100\n",
    "    return f\"https://www.ski-db.com/db/{endSeason:02d}/cal_{gender}{startSeason:02d}{endSeason:02d}.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRacesURLs(year, isMen=True):\n",
    "    \"\"\"Get all Ski-DB pages for the races of a particular season.\n",
    "    \"\"\"\n",
    "    seasonURL = getSeasonURL(year, isMen)\n",
    "    print(f\"[INFO] Getting races URLs for the {year} season\")\n",
    "    page = urllib.request.urlopen(seasonURL)\n",
    "    soup = BeautifulSoup(page)\n",
    "    races = soup.findAll(\"tbody\", {\"class\": \"skidb\"})\n",
    "\n",
    "    raceURLs = []\n",
    "    for race in races:\n",
    "        raceURLs.append(race.findAll('a')[0]['href'])\n",
    "    \n",
    "    return raceURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRace(raceURL):\n",
    "    page = urllib.request.urlopen(raceURL)\n",
    "    soup = BeautifulSoup(page)\n",
    "    raceDB = {}\n",
    "    \n",
    "    titles = soup.findAll(\"h1\")\n",
    "    if len(titles) < 2:\n",
    "        print(f\"[WARN] No metadata for {raceURL}\")\n",
    "    else:\n",
    "        metadata = titles[1].text.split(' ')\n",
    "        raceDB['date'] = ''.join(metadata[0].split('-')[::-1]).strip()\n",
    "\n",
    "        locationMetadata = ' '.join(metadata[1:])\n",
    "        raceDB['venue'] = locationMetadata.split('[')[0].strip()\n",
    "        raceDB['country'] = locationMetadata.split('-')[1].strip().split('\\n')[0].strip()\n",
    "        raceDB['event'] = locationMetadata.split('\\n')[3].strip()\n",
    "    \n",
    "    skiers = soup.findAll(\"tbody\", {\"class\": \"skidb\"})[0].findAll(\"tr\", {\"class\": [\"blanc\", \"alt\"]})\n",
    "    raceDB['results'] = {}\n",
    "    for idx, skier in enumerate(skiers):\n",
    "        info = skier.findAll(\"td\")\n",
    "        skierDB = {}\n",
    "        skierDB['rank'] = info[0].text.strip()\n",
    "        skierDB['name'] = info[1].text.strip()\n",
    "        skierDB['country'] = info[2].text.strip()\n",
    "        skierDB['data'] = [i.text.strip() for i in info[3:] if i]\n",
    "        skierDB['id'] = skier.findAll(\"a\")[0]['href'].split('/')[-1].split('.')[0]\n",
    "        raceDB['results'][idx] = skierDB\n",
    "    \n",
    "    return raceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJSON(data, filename):\n",
    "    with open(f'../data/{filename}.json', 'w+') as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSkiDB(isMen=True):\n",
    "    db = {}\n",
    "\n",
    "    for year in range(START_YEAR, END_YEAR+1):\n",
    "        yearDB = {}\n",
    "        raceURLs = getRacesURLs(year, isMen)\n",
    "        \n",
    "        for idx, raceURL in enumerate(raceURLs):\n",
    "            yearDB[idx] = parseRace(raceURL)\n",
    "        db[year] = yearDB\n",
    "        saveJSON(db, \"wcm\" if isMen else \"wcf\")\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men's Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_m = parseSkiDB(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ski-db.com/db/87/cal_m8687.php\n",
    "berlinYear = 1987\n",
    "berlinRace = 13\n",
    "\n",
    "db_m[berlinYear][berlinRace]['date']   = \"19861228\"\n",
    "db_m[berlinYear][berlinRace]['venue']  = \"Berlin\"\n",
    "db_m[berlinYear][berlinRace]['country'] = \"GER\"\n",
    "db_m[berlinYear][berlinRace]['event']  = \"Parallel\"\n",
    "\n",
    "saveJSON(db_m, \"wcm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB:\n",
    "\n",
    "- Kitzbüehl present 2 times in 19xx on 12/01/199** (?), date parsed wrongly\n",
    "- Patrick Thaler disqualifed during Adelboden Giant Slalom 1999 (1999-01-12), not 24th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Women's Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_f = parseSkiDB(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error handling**\n",
    "\n",
    "- False time for 2nd run of Elisabeth Goergl, 2010-01-16, maribor, GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.ski-db.com/db/83/918308wc.php\n",
    "tremblantYear = 1983\n",
    "tremblantRace = 22\n",
    "\n",
    "db_f[tremblantYear][tremblantRace]['date']    = \"19830305\"\n",
    "db_f[tremblantYear][tremblantRace]['venue']   = \"Mont Tremblant\"\n",
    "db_f[tremblantYear][tremblantRace]['country'] = \"CAN\"\n",
    "db_f[tremblantYear][tremblantRace]['event']   = \"Downhill\"\n",
    "\n",
    "# https://www.ski-db.com/db/83/938303wc.php\n",
    "tremblantRace = 23\n",
    "\n",
    "db_f[tremblantYear][tremblantRace]['date']    = \"19830306\"\n",
    "db_f[tremblantYear][tremblantRace]['venue']   = \"Mont Tremblant\"\n",
    "db_f[tremblantYear][tremblantRace]['country'] = \"CAN\"\n",
    "db_f[tremblantYear][tremblantRace]['event']   = \"Giant Slalom\"\n",
    "\n",
    "## The following have weird errors due to an error in the HTML\n",
    "# https://www.ski-db.com/db/09/91200903wc.php\n",
    "data = db_f['2009']['25']['results']['25']['data']\n",
    "data = data[:3]\n",
    "data[1] = data[1].split(' ')[0]\n",
    "data[2] = ''\n",
    "db_f['2009']['25']['results']['25']['data'] = data\n",
    "\n",
    "# https://www.ski-db.com/db/10/91201006wc.php\n",
    "data = db_f['2010']['24']['results']['27']['data']\n",
    "data = data[:3]\n",
    "data[1] = data[1].split(' ')[0]\n",
    "data[2] = ''\n",
    "db_f['2010']['24']['results']['27']['data'] = data\n",
    "\n",
    "saveJSON(db_f, \"wcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "1967-2003: No ski brands\n",
    "\n",
    "2003-2020: Ski brands as last index or data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/wcm.json\") as f:\n",
    "    db_m = json.load(f)\n",
    "with open(\"../data/wcf.json\") as f:\n",
    "    db_f = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLine(db, season, date, venue, country, event,\n",
    "            ath_rank=0, ath_name='', ath_country='',\n",
    "            ath_time_run_1=0, ath_time_run_2=0,\n",
    "            ath_time=0, ath_time_diff=0, ath_ski='', ath_id=''):\n",
    "    db[\"season\"].append(season)\n",
    "    db[\"date\"].append(date)\n",
    "    db[\"venue\"].append(venue)\n",
    "    db[\"country\"].append(country)\n",
    "    db[\"event\"].append(event)\n",
    "    db[\"ath_rank\"].append(ath_rank)\n",
    "    db[\"ath_name\"].append(ath_name)\n",
    "    db[\"ath_country\"].append(ath_country)\n",
    "    db[\"ath_time_run_1\"].append(ath_time_run_1)\n",
    "    db[\"ath_time_run_2\"].append(ath_time_run_2)\n",
    "    db[\"ath_time\"].append(ath_time)\n",
    "    db[\"ath_time_diff\"].append(ath_time_diff)\n",
    "    db[\"ath_ski\"].append(ath_ski)\n",
    "    db[\"ath_id\"].append(ath_id)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTimings(toParse):\n",
    "    \"\"\"Convert all times in cs (hundredths of second).\n",
    "    \"\"\"\n",
    "    if not toParse or 'n/d' in toParse:\n",
    "        return 0\n",
    "    timing = toParse.split('.')\n",
    "    time = int(timing[1][:2])\n",
    "    timing = timing[0].split(\"'\")\n",
    "    if len(timing) > 1:\n",
    "        time += int(timing[0])*6000\n",
    "        time += int(timing[1])*100\n",
    "    else:\n",
    "        time += int(timing[0])*100\n",
    "    return int(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDB(db):\n",
    "    db_parsed = {\n",
    "        \"season\": [],\n",
    "        \"date\": [],\n",
    "        \"venue\": [],\n",
    "        \"country\": [],\n",
    "        \"event\": [],\n",
    "        \"ath_rank\": [],\n",
    "        \"ath_name\": [],\n",
    "        \"ath_country\": [],\n",
    "        \"ath_time_run_1\": [],\n",
    "        \"ath_time_run_2\": [],\n",
    "        \"ath_time\": [],\n",
    "        \"ath_time_diff\": [],\n",
    "        \"ath_ski\": [],\n",
    "        \"ath_id\": [],\n",
    "    }\n",
    "    for year in range(START_YEAR, END_YEAR+1):\n",
    "        db_season = db[str(year)]\n",
    "        season = year\n",
    "        for db_race in db_season.values():\n",
    "            date = datetime.strptime(db_race['date'], \"%Y%m%d\")\n",
    "            venue = db_race['venue']\n",
    "            country = db_race['country']\n",
    "            event = db_race['event']\n",
    "            results = db_race['results']\n",
    "            if results:\n",
    "                for athlete in results.values():\n",
    "                    rank = athlete['rank']\n",
    "                    if rank.isdigit():\n",
    "                        rank = int(rank)\n",
    "                    elif rank[0] == '.':\n",
    "                        rank = int(rank[1:])\n",
    "                    name = athlete['name']\n",
    "                    ath_country = athlete['country']\n",
    "                    data = athlete['data']\n",
    "                    \n",
    "                    ath_time = data[2] if len(data) > 3 else data[0] if len(data) > 1 else None\n",
    "                    ath_time_diff = data[3] if len(data) > 3 else data[1] if len(data) > 1 else None\n",
    "                    if ath_time_diff and ath_time_diff[1:].replace('.', '').isdigit():\n",
    "                        ath_time_diff = int(ath_time_diff.replace('.', ''))\n",
    "                    elif ath_time_diff and ath_time_diff[:2] == '+-':\n",
    "                        # Fix weird bug in Ski-DB\n",
    "                        ath_time_diff = int(ath_time_diff[2:].replace('.', ''))\n",
    "                    else:\n",
    "                        ath_time_diff = 0\n",
    "                    ath_time_run_1 = data[0] if len(data) > 3 else None\n",
    "                    ath_time_run_2 = data[1] if len(data) > 3 else None\n",
    "                    ath_ski = ''\n",
    "                    if len(data) == 5:\n",
    "                        ath_ski = data[4]\n",
    "                    elif len(data) == 3:\n",
    "                        ath_ski = data[2]\n",
    "                    db_parsed = addLine(db_parsed, season, date, venue, country, event,\n",
    "                                        rank, name, ath_country, convertTimings(ath_time_run_1), convertTimings(ath_time_run_2),\n",
    "                                        convertTimings(ath_time), ath_time_diff, ath_ski, athlete['id'])\n",
    "            else:\n",
    "                db_parsed = addLine(db_parsed, season, date, venue, country, event)\n",
    "    return db_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToDF(db):\n",
    "    df = pd.DataFrame(parseDB(db))\n",
    "    df.ath_time_run_1 = df.ath_time_run_1.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = convertToDF(db_m)\n",
    "dfm.to_csv('../data/wcm.csv', index=False)\n",
    "dfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = convertToDF(db_f)\n",
    "dff.to_csv('../data/wcf.csv', index=False)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Note that all times are recorded as hundredths of seconds, as to not lose any precision with floating point numbers.\n",
    "\n",
    "To discuss: ranks are not integers beacause they contain information on DNFs, etc. Should we convert them  to integers and hold the extra information in another column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseCSV(isMale=True):\n",
    "    gender = 'm' if isMale else 'f'\n",
    "    df = pd.read_csv(f'../data/wc{gender}.csv')\n",
    "    df = df.replace(np.nan, '', regex=True)\n",
    "    df.date = pd.to_datetime(df.date, format='%Y-%m-%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = parseCSV()\n",
    "dff = parseCSV(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm['ath_rank'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[(dff.)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(10000)\n",
    "def getSearchSoup(firstname, lastname, gender):\n",
    "    g = 'M' if gender else 'F'\n",
    "    url = f\"https://www.fis-ski.com/DB/general/biographies.html?lastname={lastname}&firstname={firstname}&sectorcode=AL&gendercode={g}&search=true\"\n",
    "    page = urllib.request.urlopen(url)\n",
    "    return BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAthleteInfo(firstname, lastname, gender):\n",
    "    try:\n",
    "        soup = getSearchSoup(firstname, lastname, gender)\n",
    "    except:\n",
    "        print(f\"[ERR] Could not parse {firstname} {lastname}\")\n",
    "        return None, 'ENC'\n",
    "    entries = soup.findAll(\"a\", {\"class\": \"table-row\"})\n",
    "    if len(entries) == 0:\n",
    "        return None, 'ERR'\n",
    "    if len(entries) > 1:\n",
    "        return None, 'WAR'\n",
    "    info = entries[0].find('div').findAll('div')\n",
    "    return info[3].find(text=True), info[8].find(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherNames(gender):\n",
    "    g = 'm' if gender else 'f'\n",
    "    wc = pd.read_csv(f'../../data/wc{g}.csv')\n",
    "    names = list(set(wc.ath_name.tolist()))[1:]\n",
    "    searchNames = {}\n",
    "    for n in names:\n",
    "        split_n = n.strip().split(' ')\n",
    "        searchNames[n] = split_n[0], split_n[-1]\n",
    "    return searchNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatherInfo(gender):\n",
    "    searchNames = gatherNames(gender)\n",
    "    found = {}\n",
    "    error = {}\n",
    "    for name, (fn, ln) in searchNamesM.items():\n",
    "        id, bd = getAthleteInfo(fn, ln, True)   \n",
    "        if id:\n",
    "            found[name] = id, bd\n",
    "        else:\n",
    "            error[name] = id, bd\n",
    "    return found, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERR] Could not parse HÅkon Mjoen\n"
     ]
    }
   ],
   "source": [
    "foundMale, errorMale = gatherInfo(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR: 170\n",
      "WAR: 170\n",
      "ENC: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'ERR: {sum([1 for name, (a, err) in errorMale.items() if err == \"ERR\"])}')\n",
    "print(f'WAR: {sum([1 for name, (a, err) in errorMale.items() if err == \"ERR\"])}')\n",
    "print(f'ENC: {sum([1 for name, (a, err) in errorMale.items() if err == \"ENC\"])}')\n",
    "#for name, (a, err) in errorMale:\n",
    "#    if err == \"WAR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ath_db = {\n",
    "    'names': [],\n",
    "    'ids': [],\n",
    "    'bds': [],\n",
    "}\n",
    "for name, (id, bd) in foundMale.items():\n",
    "    ath_db['names'].append(name)\n",
    "    ath_db['ids'].append(id)\n",
    "    ath_db['bds'].append(bd)\n",
    "for name, (id, bd) in errorMale.items():\n",
    "    ath_db['names'].append(name)\n",
    "    ath_db['ids'].append(id)\n",
    "    ath_db['bds'].append(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ath_db).to_csv('ath_male.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
